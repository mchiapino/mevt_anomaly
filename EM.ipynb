{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import mystic.solvers as ms\n",
    "import os\n",
    "\n",
    "import generate_alphas as ga\n",
    "import mom_constraint as mc\n",
    "import extreme_data as extr\n",
    "import damex_algo as dmx\n",
    "import clef_algo as clf\n",
    "import em_algo as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 42, 18, 16, 8, 14, 8, 4, 0, 5, 6, 3, 5, 6, 3, 6, 13, 2]\n"
     ]
    }
   ],
   "source": [
    "# Airbus Data\n",
    "x = genfromtxt('Data_Anne.csv', delimiter=',')\n",
    "x = x[1:, 1:]\n",
    "n, d_0 = np.shape(x)\n",
    "\n",
    "# Each feature is doubled, separating points above and below the mean\n",
    "mean = np.mean(x, axis=0)\n",
    "var = x - mean\n",
    "x_doubled = np.zeros((n, 2*d_0))\n",
    "for j in range(d_0):\n",
    "    x_doubled[var[:, j] > 0, j] = var[var[:, j] > 0, j]\n",
    "    x_doubled[var[:, j] < 0, d_0 + j] = - var[var[:, j] < 0, j]\n",
    "\n",
    "# Rank transformation, for each margin (column) V_i = n/(rank(X_i) + 1)\n",
    "x_rank_0 = extr.rank_transformation(x_doubled)\n",
    "\n",
    "# kth extremer points for the sum-norm\n",
    "k_0 = int(1e3)\n",
    "ind_extr_0 = np.argsort(np.sum(x_rank_0, axis=1))[::-1][:k_0]\n",
    "x_extr_0 = x_rank_0[ind_extr_0]\n",
    "\n",
    "# Sparse support\n",
    "R_spars = np.min(np.max(x_extr_0, axis=1)) - 1\n",
    "# Damex\n",
    "eps_dmx = 0.5\n",
    "mu_min = 0.003\n",
    "alphas_0, mass = dmx.damex(x_extr_0, R_spars, eps_dmx, mu_min=mu_min)\n",
    "K_dmx = np.sum(mass > 3)\n",
    "alphas_dmx = clf.find_maximal_alphas(dmx.list_to_dict_size(alphas_0))\n",
    "print([np.sum(np.sum(x_extr_0[:, alpha] > R_spars, axis=1) == len(alpha))\n",
    "       for alpha in alphas_dmx])\n",
    "# # Clef\n",
    "# kappa_min = 0.3\n",
    "# alphas_clf = clf.clef(x_extr_0, R_spars, kappa_min)\n",
    "# print [np.sum(np.sum(x_extr_0[:, alpha] > R_spars, axis=1) == len(alpha))\n",
    "#        for alpha in alphas_clf]\n",
    "\n",
    "# Extreme points; Only keeps features that appear in the alphas\n",
    "alphas_0 = alphas_dmx\n",
    "feats = list(set([j for alph in alphas_0 for j in alph]))\n",
    "d = len(feats)\n",
    "x_rank = x_rank_0[:, feats]\n",
    "k_1 = int(500)\n",
    "ind_extr = np.argsort(np.sum(x_rank, axis=1))[::-1][:k_1]\n",
    "np.save('results/ind_extr.npy', ind_extr)\n",
    "x_extr = x_rank[ind_extr]\n",
    "np.save('results/extr_data.npy', x_extr)\n",
    "alphas = ga.alphas_conversion(alphas_0)\n",
    "np.save('results/alphas.npy', alphas)\n",
    "mat_alphas = ga.alphas_matrix(alphas)\n",
    "alphas_singlet = []\n",
    "K = len(alphas)\n",
    "K_tot = K + len(alphas_singlet)\n",
    "\n",
    "# # Extreme points with singlets\n",
    "# alphas = alphas_clf\n",
    "# K = len(alphas)\n",
    "# d = 2*d_0\n",
    "# feats = list(set([j for alph in alphas for j in alph]))\n",
    "# alphas_singlet = [[j] for j in list(set(range(2*d_0)) - set(feats))]\n",
    "# K_tot = K + len(alphas_singlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -3067.978072\n",
      "         Iterations: 279\n",
      "         Function evaluations: 10301\n",
      "-215714.28392695327 -193318.2799990253\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1896.708321\n",
      "         Iterations: 815\n",
      "         Function evaluations: 36607\n",
      "-199774.40020440868 -182770.3979227157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1968.647294\n",
      "         Iterations: 844\n",
      "         Function evaluations: 38025\n",
      "-202515.07144368428 -183768.14117094787\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1813.402086\n",
      "         Iterations: 846\n",
      "         Function evaluations: 38115\n",
      "-201176.6032881673 -183173.36717288004\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -1753.233415\n",
      "         Iterations: 1004\n",
      "         Function evaluations: 45225\n",
      "-199817.5562728134 -182620.74537870885\n"
     ]
    }
   ],
   "source": [
    "x_extr = np.load('results/extr_data.npy')\n",
    "n_extr, d = x_extr.shape\n",
    "alphas = np.load('results/alphas.npy')\n",
    "K = len(alphas)\n",
    "K_tot = K\n",
    "alphas_singlet = []\n",
    "\n",
    "# Empirical rho\n",
    "means_emp = [np.mean(em.project_on_simplex(x_extr, alpha), axis=0)\n",
    "             for alpha in alphas]\n",
    "weights_emp = np.ones(K)/K\n",
    "rho_emp = mc.means_weights_to_rho(means_emp, weights_emp, alphas)\n",
    "\n",
    "# Rho that verify moment constraint\n",
    "rho_init = mc.project_rho(rho_emp, d)\n",
    "\n",
    "# Init\n",
    "nu_init = 20*np.ones(K)\n",
    "theta_init = mc.rho_nu_to_theta(rho_init, nu_init, alphas)\n",
    "lbda_init = 0.01*np.ones(K_tot)\n",
    "noise_func = 'expon'\n",
    "gamma_z_init = em.compute_gamma_z(x_extr, theta_init, lbda_init,\n",
    "                                  alphas, alphas_singlet,\n",
    "                                  noise_func)\n",
    "Q_tot = em.Q_tot(theta_init, lbda_init, x_extr, gamma_z_init,\n",
    "                 alphas, alphas_singlet,\n",
    "                 noise_func)\n",
    "cplt_lhood = em.complete_likelihood(x_extr, theta_init, lbda_init,\n",
    "                                    alphas, alphas_singlet,\n",
    "                                    noise_func)\n",
    "\n",
    "# Constraints\n",
    "theta_constraint = mc.Theta_constraint(alphas, d)\n",
    "\n",
    "# Bounds\n",
    "bds_r = [(0, 1./d) for i in range(len(theta_init[:-K]))]\n",
    "bds_n = [(0, 100) for i in range(K)]\n",
    "bds = bds_r + bds_n\n",
    "n_loop = 5\n",
    "\n",
    "# EM algorithm\n",
    "gamma_z = np.copy(gamma_z_init)\n",
    "lbda = np.copy(lbda_init)\n",
    "theta = np.copy(theta_init)\n",
    "gamma_z_list = [gamma_z]\n",
    "lbda_list = [lbda]\n",
    "theta_list = [theta]\n",
    "check_list = [(-Q_tot, cplt_lhood)]\n",
    "cpt = 0\n",
    "crit_diff = 2.\n",
    "while crit_diff > 1. and cpt < n_loop:\n",
    "    # E-step\n",
    "    gamma_z = em.compute_gamma_z(x_extr, theta, lbda,\n",
    "                                 alphas, alphas_singlet,\n",
    "                                 noise_func)\n",
    "    gamma_z_list.append(gamma_z)\n",
    "    # M-step\n",
    "    # Minimize in lambda\n",
    "    if noise_func == 'expon':\n",
    "        lbda = em.compute_new_lambda(x_extr, gamma_z,\n",
    "                                     alphas, alphas_singlet)\n",
    "    if noise_func == 'pareto':\n",
    "        lbda = em.compute_new_pareto(x_extr, gamma_z,\n",
    "                                     alphas, alphas_singlet)\n",
    "    lbda_list.append(lbda)\n",
    "    # Minimize in theta\n",
    "    theta = ms.diffev(em.Q, theta,\n",
    "                      args=(x_extr, gamma_z, alphas),\n",
    "                      bounds=bds,\n",
    "                      constraints=theta_constraint)\n",
    "    theta_list.append(theta)\n",
    "    # New likelihood\n",
    "    Q_tot_ = em.Q_tot(theta, lbda, x_extr, gamma_z,\n",
    "                      alphas, alphas_singlet,\n",
    "                      noise_func)\n",
    "    cplt_lhood_ = em.complete_likelihood(x_extr, theta, lbda,\n",
    "                                         alphas, alphas_singlet,\n",
    "                                         noise_func)\n",
    "    crit_diff = abs(Q_tot_ - Q_tot)\n",
    "    Q_tot = Q_tot_\n",
    "    cplt_lhood = cplt_lhood_\n",
    "    print(-Q_tot, cplt_lhood)\n",
    "    check_list.append((-Q_tot, cplt_lhood))\n",
    "    cpt += 1\n",
    "np.save('results/gamma_z_dmx.npy', gamma_z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:evt]",
   "language": "python",
   "name": "conda-env-evt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
